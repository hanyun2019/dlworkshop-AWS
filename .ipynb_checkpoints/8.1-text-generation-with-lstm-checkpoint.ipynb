{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "[...]\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a \n",
    "language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this \n",
    "example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model \n",
    "we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the \n",
    "English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 1s 2us/step\n",
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How do you know the download directory of your Jupyter notebook? \n",
    "$ find / -name nietzsche.txt >> Chapter8-1-output.txt\n",
    "$ cat Chapter8-1-output.txt\n",
    "/home/ubuntu/.keras/datasets/nietzsche.txt\n",
    "\n",
    "Next, we will extract partially-overlapping sequences of length `maxlen`, one-hot encode them and pack them in a 3D Numpy array `x` of \n",
    "shape `(sequences, maxlen, unique_characters)`. Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot \n",
    "encoded characters that come right after each extracted sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Our network is a single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters. But let us note that \n",
    "recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in \n",
    "recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "* 1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "* 2) Reweighting the distribution to a certain \"temperature\"\n",
    "* 3) Sampling the next character at random according to the reweighted distribution\n",
    "* 4) Adding the new character at the end of the available text\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, \n",
    "and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures \n",
    "after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of \n",
    "temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 84s 418us/step - loss: 1.9436\n",
      "--- Generating with seed: \"n\n",
      "itself as the goal and standard of things, and smugly and \"\n",
      "------ temperature: 0.2\n",
      "n\n",
      "itself as the goal and standard of things, and smugly and the cance and and in the generation of the cance and the faith the spirity the same that is the generate that is and man and in the conscience the cansing and and the stander the consciention of the still the can the consequent\n",
      "should the standing of the wermantion of the preasious and man in the cansing that is all the self-religion of the stronged and the self-even of the conscience of the cansi\n",
      "------ temperature: 0.5\n",
      "he stronged and the self-even of the conscience of the cansions of the preaing and self--innot perhaps which the concemous abon that lated in the former the most science that as a partion is the uned. the accate the one is and the preession, and an even of the has all the endiged the mand on the philosophy his eread and selfestity--as the conscieming in the same the man in the mands and the and in a conscious of the spirition. for his one that is as a mean\n",
      "------ temperature: 1.0\n",
      " a conscious of the spirition. for his one that is as a means of  ginaoonation, hestand is though of cance outracl--brougat. there action. of and freeation--res-bleed and anclurdate strences of this is not the imstance and praid. thus irle in wh camely of their something bellasted hive which may that these least eporationed is i veltens, wite antempredous for it\n",
      "  reward reveitional. butdor plitule in powility. the will be, who afferous, what discinings an\n",
      "------ temperature: 1.2\n",
      "e in powility. the will be, who afferous, what discinings and apstivation and acl agone\n",
      "oppreysion; liye is repallully n0by proitencatihed. and pra inapuse th2 gliuble on flue actande--b. her infut. he  leas fut her le foursbe hind ond brought, werx, has and diinity\" \"joded. the eevligioner light--thing find he\n",
      "dethitxve--as wask. agoations,\" and.-wilc,\n",
      "in fealoking, yey its dayed, denist: nunthing, beness of casibe-for been wanderhope tainlon\" ungraitol, \n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 416us/step - loss: 1.6124\n",
      "--- Generating with seed: \"to sum up all that has been said=: that condition of soul at\"\n",
      "------ temperature: 0.2\n",
      "to sum up all that has been said=: that condition of soul at the despired and present and and and the despires and an and despirition of the contemptions of the man and and as a most senses the species and the presention of the senses the senses and desciently and the senses of the despired and presention of the feeling in the presention of the descession of the senses the despiration of the religious and and and sensitions of the free the presention of th\n",
      "------ temperature: 0.5\n",
      "ious and and and sensitions of the free the presention of the heristed, and an one to the furtionaly that it is the beations and from the restrence been in the life and devilor amany and happiness itself, and an\n",
      "above a sensition is the most whe who can are the general been want of the been he respectives and acts and implession and an age as the germans and the desperitions to the every despire and an intiment and trace and the beates and unto succe, whic\n",
      "------ temperature: 1.0\n",
      "nd an intiment and trace and the beates and unto succe, which refame\n",
      "cirrecound, it had at sagixtients of latter, the peaseded and\n",
      "an\n",
      "philosophisio the irpoliness of nom the respiry may rangered to ye origate.\n",
      "\n",
      "1h arnes\n",
      "many bright?\n",
      "\n",
      "    not yeumbul manmbunce\n",
      "time a kindst one \"quiemy; in which he san, hows specipal but whengreser have wearable: for with the facclerbals cunsame of pribes of dispidity seart from the diffecritations and one tragek not mankin\n",
      "------ temperature: 1.2\n",
      "ity seart from the diffecritations and one tragek not mankin:tifits,\n",
      "us an in tose up the\n",
      "e, fo, to chsent, and ourselves with their lipe, hi rlowed\n",
      "is\n",
      "others--the \n",
      ")peues sure\n",
      "yer ered rempixative undartys whe casisu most he discrunally, than have the, mas gevel= truth ours antirely differented. sdepth willod, hardlye\n",
      "sus cundaming if the\n",
      "wiltych wiske. it\n",
      "nettere you; intentle tones\n",
      "highest thufug of moxe f)irs as all\" above of genere a chrissian su, bef\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 415us/step - loss: 1.5273\n",
      "--- Generating with seed: \"t and dangerous sign of the lack thereof. it is not the work\"\n",
      "------ temperature: 0.2\n",
      "t and dangerous sign of the lack thereof. it is not the work and sense of the sense of the sense of the sense of the sense of the sense of the sense of the men and sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the men as in the men as in the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of\n",
      "------ temperature: 0.5\n",
      "sense of the sense of the sense of the sense of the sense of only the ling are are longer belief in mong the consision of supposing the present the semility of one as the sense of all the man in the herting in the very divent the most child and of the feels the conception and truth because and will be longer as in the personal taken, and desirable and experience and the dispresed and men of all the same and also the continual too the stricts of the whole s\n",
      "------ temperature: 1.0\n",
      "e same and also the continual too the stricts of the whole spondinidity. the low no ligete can a profound eirllurg dongunal togethily eople, as it moltakes at love their un\n",
      "also consequentlent rare for noways they arerely penlone are nothing its merious ab ill be regards to rendered of the senten naters within the floon in zendes\n",
      "are nothhteks himself of whrought intained. the most mivebut ?naivespine uscbriald to it to seart\n",
      "to of 'est reven. for should s\n",
      "------ temperature: 1.2\n",
      "pine uscbriald to it to seart\n",
      "to of 'est reven. for should shem christianmem means of most rearte\n",
      "afterpoiss, nothing,\n",
      "and feels  on; towartess commandent of all triught what his illed of all loyes mabser in are trutus iepor concers\n",
      "precis, has most a one knowseff men that chumran un\n",
      "not selmed in icmean enounal in. whens throught, at phisoush ankint of a ismines the aed arrvess, a)men knowledge, evis one argwicuse: imout in our oh\n",
      "interement earchuping of\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 414us/step - loss: 1.4814\n",
      "--- Generating with seed: \"illing--to such a degree\n",
      "that he who wills believes firmly t\"\n",
      "------ temperature: 0.2\n",
      "illing--to such a degree\n",
      "that he who wills believes firmly that which is the same the superiorial and the superiorical and in the same the same the are the same the most disconsible and and allowed the consider and discovered to be the same the same the superiorian and allowed by the consider and the superiory of the superited and prope to the experience of the subject and are the consider the are the same the superiory of the same the consider and in the \n",
      "------ temperature: 0.5\n",
      " the same the superiory of the same the consider and in the respect to be the present as a symptaps a one become the history, all the take a see in the anciently in the superiorian of the same the history, who who are such and morality in the loble and that is allowed to have with the thought and strongly because and or \"can from a causious have the experience of our of the experience that is not the consided hitherto been the the child a new experiences t\n",
      "------ temperature: 1.0\n",
      "the consided hitherto been the the child a new experiences that what, has acmority, which all the keep uppored, appetenory ut ever, as one a solthasion counter. in\n",
      "viewn of\n",
      "philogo-arristiced for recial. the lastongual country of vision, on the exception of\n",
      "ellessish most very perplese of\n",
      "which than with which\n",
      "is the sa-hys obligation of the moss\n",
      "of one has considion\n",
      "clep it is sick and \"morality; in recide.\n",
      "selugees squehs\" of will moors the has\n",
      "sperity, \n",
      "------ temperature: 1.2\n",
      " in recide.\n",
      "selugees squehs\" of will moors the has\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sperity, practs into a bedrerly whatit socieal own phqusi's akdre, but has : sre his consciousness that let pessims of a. not would no lafed\n",
      "whythur asomish-regarded, soul of been, knowledged, procound of must how are objertly, wronks of helled disposing bmins most sorrricticrheness.--such an sto:, even cleady ha.\n",
      "those youlo\n",
      "curitscince alwayss:, that take is o cuursory as cale cerenial.\n",
      "\n",
      "good oftery stra\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 415us/step - loss: 1.3972\n",
      "--- Generating with seed: \"our neighbour. after the fabric of society seems on the\n",
      "whol\"\n",
      "------ temperature: 0.2\n",
      "our neighbour. after the fabric of society seems on the\n",
      "whole of the sense of such a soul himself and interpretation of the sense of the sense of the sense of the sense of the fact of the present in the man with the desires and precisely and sense of the sense of the sense of the sense of the precisely and the father the sense of the sense of the sense of the sense of the sense of the sense of the sense of the moral and the sense of the sense of the sense \n",
      "------ temperature: 0.5\n",
      " sense of the moral and the sense of the sense of the sense of the whole and sense and same the philosophers are sought to say and man as a such men of the sense and to say to his desires there are still seems a man may perhaps one of present and put the serve himself and speak there is nothing in humanity, and in same in the spirit and most silence and part of the same will be the passion of the sense of the soul and noble specially account be so on the p\n",
      "------ temperature: 1.0\n",
      "sense of the soul and noble specially account be so on the phenolousice--ye with offersm oferatjonsing--he much exist\n",
      "to it, when the commanders, at no soul be sense, the oub dences. a great sendered and sund it. which out of the sormour to may be a telutions as\n",
      "highem constutime the degree insimite\n",
      "a (and indesiefuced, and there passion.doust be, and of the trebound may be\n",
      "speak,\n",
      "certainly teachather as\n",
      "to its formul. it usual, noor sayss of sinifical sed\n",
      "------ temperature: 1.2\n",
      "ther as\n",
      "to its formul. it usual, noor sayss of sinifical seduccescendest\n",
      "\"sympathflabits, it jee, but it\n",
      "perprewanded against a vasue, of suffering, every man\n",
      "endables, igonceptires; and speaks--gains, as mobe soielquernations which ! groups. be : ills the a virtuous were -kinds of the need up. the\n",
      "dastiness inyompore speakined semitunity of sighten, yow write relation of fact of singely, our piety\n",
      "as follictousnced, but mazeousness is suny frre at on dise\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "163200/200278 [=======================>......] - ETA: 15s - loss: 1.3829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200278/200278 [==============================] - 83s 415us/step - loss: 1.3686\n",
      "--- Generating with seed: \"level of\n",
      "the \"man of the future\"--as idealized by the social\"\n",
      "------ temperature: 0.2\n",
      "level of\n",
      "the \"man of the future\"--as idealized by the sociality of the same the superfact to the contempt to the spirit to the same the self-contempt to the same the self-strong the spirit, the same the self-pertainly and the self-contempt to the same the spirit to the same to the superfaction of the self-evilticed to the same does the spirit of the same the spirit to the self-contempt to the self-same the desires to the same the fact of the same the perso\n",
      "------ temperature: 0.5\n",
      "-same the desires to the same the fact of the same the personal of the truth the preferstune to distingual charatt hardly necessity. the later word to the delight, the spirit to may be purpeacate morality, the same wild\n",
      "to the conscience of the worss of all the word soul perhaps\n",
      "to the strength and sufferiors of the self-nature, the sear of which the soul and thing the recombides to discovered rather in the present and believed and the desiring and species\n",
      "------ temperature: 1.0\n",
      "her in the present and believed and the desiring and species--every most the expegis of almost\n",
      "worth and possess without had to rt\n",
      "trushction,\n",
      "but the\n",
      "let moble means his soul latte--of it. they be iach\n",
      "liveses anxisiture, as mistake (and destanch perhaps, that they fainy effect of the mison\"--namely at\n",
      "every passed to . for the tourly into the facules to be best psighing with law extamed, usantifical.\n",
      "\n",
      "ye ayptical tes;ure at the balding in its politics in\n",
      "------ temperature: 1.2\n",
      "ical.\n",
      "\n",
      "ye ayptical tes;ure at the balding in its politics in crisismation to pres bound; the svily of timeity in fact aichtingual hoph--already inportance the fear--hench, there are even the rulives, let at to alone one drigoon that\n",
      "namies. outtlerat of lack, , but, that the\n",
      "own\n",
      "d\"ferting \"tage furrigns. no derising it, toweed years of the\n",
      "advoutive buty. \"in dischean--thing which conducted, esciest. our securiture and cla, facts feers). \"wishitude, for un\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 415us/step - loss: 1.3606\n",
      "--- Generating with seed: \"nd the apparent world\" is dealt with at\n",
      "present throughout e\"\n",
      "------ temperature: 0.2\n",
      "nd the apparent world\" is dealt with at\n",
      "present throughout expeding the prove the strength and strength and any one another and the sense of the spirit and the fact the same the same the complete the respect to the progression the progression of the strength of the sense of the surplus and the sense of the same the spirit of the sort of the strength of the former the fact to the man and the sense of the sense of the process of the surface of the self-cours\n",
      "------ temperature: 0.5\n",
      "of the sense of the process of the surface of the self-course and more like of the best distinguish the sense and strong the will to his fatholity of a man of a man with regard to the most and of the solentation and will the promise and acts of the expressing and the notion of the socrations and wanting the most flooriating the honour of the other and ever to love thereby all the germany of the values, so far as they are attain with the fellow of the way i\n",
      "------ temperature: 1.0\n",
      "lues, so far as they are attain with the fellow of the way in his descrows.\n",
      "\n",
      "keless to they an free to an ladially now\n",
      "form and back of hor which i have\n",
      "has one another mponsing tnoneslatol\n",
      "incausited\n",
      "significancenism for the sick, and conkisness leed to the moremy when she--they throng or ro\n",
      "call an\n",
      "amiptinable right that the mads,\" as the inlige\" some temporarical torfities of the right to\n",
      "individual impre.k wherepply they not the threed by a mys\n",
      "effect,\n",
      "------ temperature: 1.2\n",
      "idual impre.k wherepply they not the threed by a mys\n",
      "effect, and norts, word and higher in-nay, andly are would niteled skeptire-centle are strength, assertions it, writh\n",
      "to be dustness powerful man extrisces,\n",
      "and it whereevines partring to aim\n",
      "far has weqoual; and religit last\n",
      "moorical in very oke throcar for you juttines that leavned \"it, i naushing-way--manys order there disinistoverary with higher faurhin manwame rank whone homschivim. sebkenes ambi\":\n",
      "\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 83s 415us/step - loss: 1.3544\n",
      "--- Generating with seed: \"shown himself powerless and have ranked as such thenceforwar\"\n",
      "------ temperature: 0.2\n",
      "shown himself powerless and have ranked as such thenceforward the self delicate the spirit of the spirit and still strong the spirit and more soul and the contems and present and soul is a man who are all indept of the spirit to be the self-contention of the faculty and still strong the present the extent and strength and something in the same strength of the spirit and single of the sense in the present the more and present and in the soul and in the cons\n",
      "------ temperature: 0.5\n",
      "present the more and present and in the soul and in the conscience of the god\" and an intentions, and the world of such a still the truth and exercised and seriously of philosophers--the masters of its belief as the spirit to really to be the reverence what part of respection of the sense the means of a delicate to case of the have in such an intentionally be a philosophering a surdinged the englishes and disciplience of present of the present its far from\n",
      "------ temperature: 1.0\n",
      "shes and disciplience of present of the present its far from a  even own--and impertihe engevere\". thereferi, new, this another scenite foreligh injure almost their considerive, and\n",
      "his time naturdles, how bad and\n",
      "obsilizes.\" in the values--if the far degreemer from tworv, spirit. also, and we make the din.\" are best ten another worked considerary of regire, to stupidity.=--a thiase comment the profound, on the mognist; nesteres, from self\n",
      "altey stacce whi\n",
      "------ temperature: 1.2\n",
      "ofound, on the mognist; nesteres, from self\n",
      "altey stacce which the spirits, loind. but ye\n",
      "the names, all\n",
      "overwima dictumying with laugaly--the eamold without utlew an iabl errok the hudle no. greather of the\n",
      "friendr, solemantoral existonate dangeist moralism,materenged doe by the\n",
      "way-cattly of wear or this pose quality, whose has bounce is the slaver of thuss.=--liths many comprehile asong pehcance aidly\n",
      "arougher suigences, its were faith a wyle that my ot\n",
      "epoch 14\n",
      "Epoch 1/1\n",
      " 53888/200278 [=======>......................] - ETA: 1:00 - loss: 1.3202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9486ed95c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     model.fit(x, y,\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               epochs=1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Select a text seed at random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, a low temperature results in extremely repetitive and predictable text, but where local structure is highly realistic: in \n",
    "particular, all words (a word being a local pattern of characters) are real English words. With higher temperatures, the generated text \n",
    "becomes more interesting, surprising, even creative; it may sometimes invent completely new words that sound somewhat plausible (such as \n",
    "\"eterned\" or \"troveration\"). With a high temperature, the local structure starts breaking down and most words look like semi-random strings \n",
    "of characters. Without a doubt, here 0.5 is the most interesting temperature for text generation in this specific setup. Always experiment \n",
    "with multiple sampling strategies! A clever balance between learned structure and randomness is what makes generation interesting.\n",
    "\n",
    "Note that by training a bigger model, longer, on more data, you can achieve generated samples that will look much more coherent and \n",
    "realistic than ours. But of course, don't expect to ever generate any meaningful text, other than by random chance: all we are doing is \n",
    "sampling data from a statistical model of which characters come after which characters. Language is a communication channel, and there is \n",
    "a distinction between what communications are about, and the statistical structure of the messages in which communications are encoded. To \n",
    "evidence this distinction, here is a thought experiment: what if human language did a better job at compressing communications, much like \n",
    "our computers do with most of our digital communications? Then language would be no less meaningful, yet it would lack any intrinsic \n",
    "statistical structure, thus making it impossible to learn a language model like we just did.\n",
    "\n",
    "\n",
    "## Take aways\n",
    "\n",
    "* We can generate discrete sequence data by training a model to predict the next tokens(s) given previous tokens.\n",
    "* In the case of text, such a model is called a \"language model\" and could be based on either words or characters.\n",
    "* Sampling the next token requires balance between adhering to what the model judges likely, and introducing randomness.\n",
    "* One way to handle this is the notion of _softmax temperature_. Always experiment with different temperatures to find the \"right\" one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
